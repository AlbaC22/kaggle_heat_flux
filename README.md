# **Feature Imputation with a Heat Flux DatasetğŸ§©ğŸŒ¡ï¸**

Â¡Hola! ğŸ‘‹ En este proyecto de Kaggle, me enfrentÃ© al desafÃ­o de tratar valores faltantes en un dataset de 10 columnas y 31644 filas, procedente de otro dataset de 1865 filas y las mismas columnas.
PermÃ­teme resumirte cÃ³mo abordÃ© el problema y resolvÃ­ la imputaciÃ³n de missing values utilizando diferentes tÃ©cnicas; asÃ­ como los modelos de aprendizaje automÃ¡tico que utilicÃ© para predecir la variable objetivo. Â¡Comencemos! ğŸš€

**ğŸ“ Breve descripciÃ³n del proyecto:**

Este trabajo se enfoca en predecir la mÃ¡xima cantidad de calor que puede transferirse en sistemas de ebulliciÃ³n antes de que ocurran problemas. ğŸš«ğŸ˜“

 Utiliza una combinaciÃ³n de conocimiento experto y tÃ©cnicas de aprendizaje automÃ¡tico para mejorar las predicciones.  ğŸ¤–

 Se analizan diferentes variables, como la geometrÃ­a del sistema y la presiÃ³n, para desarrollar un modelo preciso. 

 El objetivo es utilizar estos datos para diseÃ±ar sistemas de calentamiento mÃ¡s seguros y eficientes en diferentes industrias.

 ![heat_flux](img/HeatFlux.jpg)
## **ğŸ’¡ ResoluciÃ³n del problema:**

El dataset consta de columnas categÃ³ricas y numÃ©ricas, con una columna objetivo llamada "x_e_out [-]". Se observÃ³ que todas las columnas tenÃ­an valores nulos, excepto "chf_exp [MW/m2]". El porcentaje de valores nulos en las columnas rondaba el 15%.

## **ğŸ› ï¸ Proceso de imputaciÃ³n de valores faltantes:**

Sabemos que existe un dataset original con 1865 entradas y las mismas columnas. Por lo tanto, podemos usarlo como referencia para imputar los valores faltantes en el dataset de 31644 filas; ya que hemos comprobado que el dataset generado contiene al original como subconjunto.

![distribuciÃ³n](img/numerical_feature_distribution_orig_and_generated.png)

**Cuando las variables no siguen una correlaciÃ³n lineal clara, imputar los valores nulos con medidas de estadÃ­stica descriptiva puede introducir sesgos en los datos imputados.â€‹**

![pairplot](img/pairplot.png)
**Excepto por las columnas ``D_e [mm]`` y ``D_h [mm]``, las demÃ¡s no siguen una correlaciÃ³n lineal clara. Por lo tanto, no podemos imputar los valores faltantes con medidas de estadÃ­stica descriptiva.**


**1ï¸âƒ£ğŸ”¹ Columnas categÃ³ricas (author y geometry):**

UtilicÃ© el valor mÃ¡s frecuente ``(moda)`` para imputar los valores faltantes en estas columnas. A travÃ©s de un pipeline, apliquÃ© SimpleImputer con la estrategia 'most_frequent' para reemplazar los valores nulos.
Sin embargo, para los valores faltantes de ``geometry`` en los que existÃ­a informaciÃ³n de las columnas ``D_h [mm]`` y ``D_e [mm]``, utilicÃ© la siguiente lÃ³gica:

![geometry_d_h_d_e](img/dh_de_geometry.png)
* **Cuando 'geometry' es 'tube', los valores de 'D_e [mm]' y 'D_h [mm]' son iguales.**

* **Cuando 'geometry' es 'annulus', los valores de 'D_h [mm]' son generalmente mayores que los valores de 'D_e [mm]'.**

* **Para la categorÃ­a 'plate', solo hay un caso registrado y los valores de 'D_h [mm]' y 'D_e [mm]' son iguales.** (15, 120)
  

**Mediante esta matriz de nulos, imputamos los valores nulos de ``geometry`` para ``D_h [mm]`` y ``D_e [mm]`` informados usando la lÃ³gica anterior.**

![null_matrix](img/geometry_en_base_a_dh_y_de.png)


**2ï¸âƒ£Columnas numÃ©ricas no correlacionadas linealmente:**

Para las columnas numÃ©ricas no linealmente correlacionadas: ``pressure [MPa]``, ``mass_flux [kg/m2-s]``, y ``length [mm]``, implementÃ© **``KNN (K-Nearest Neighbors)``** para la imputaciÃ³n. Usando otro pipeline, configurÃ© KNNImputer con 5 k-vecinos mÃ¡s cercanos y pesos uniformes para reemplazar los valores faltantes.



 **3ï¸âƒ£Columnas numÃ©ricas correlacionadas linealmente:**

Nos hemos fijado en el patrÃ³n que siguen los datos del dataset original y generado y son iguales. 

Por lo tanto, podemos utilizar esta informaciÃ³n para imputar los valores faltantes en las columnas numÃ©ricas correlacionadas linealmente:
``D_e [mm]`` y ``D_h [mm]``


![dh_de](img/lineal_de_dh.png)



#### **ğŸ“ Geometry == 'plate'** â¡ï¸ (``D_e [mm]``=15; ``D_h [mm]`` = 120)

![plate](img/geometry_igual_plate_generado.png)

#### **ğŸ“ Geometry == 'tube'** â¡ï¸ (``D_e [mm]``=``D_h [mm]``)

![tube](img/geometry_igual_tube_generado.png) 


#### **ğŸ“ Geometry == 'annulus'** â¡ï¸ (``D_e [mm]``<``D_h [mm]``)

![annulus](img/geometry_igual_annulus_generated.png)

### âœ… D_h [mm] = k * D_e [mm] â¡ï¸ RegresiÃ³n Lineal
Hemos calculado el valor de k mediante la regresiÃ³n lineal de las columnas ``D_e [mm]`` y ``D_h [mm]`` en el dataset original.
Entrenamos en el modelo original e imputamos en el generado


### âœ… D_e [mm] = a + b * D_h [mm] â¡ï¸ RegresiÃ³n Lineal Inversa
Hemos calculado los valores de a y b mediante la regresiÃ³n lineal inversa de las columnas ``D_e [mm]`` y ``D_h [mm]`` en el dataset original. Impusimos los valores en el dataset generado.

### âœ… D_e [mm] y D_h [mm] = null â¡ï¸ KNN
Para los valores faltantes de ``D_e [mm]`` y ``D_h [mm]``, utilicÃ© nuevamente KNNImputer con 5 k-vecinos mÃ¡s cercanos y pesos uniformes para reemplazar los valores faltantes.


**4ï¸âƒ£Columnas numÃ©ricas no linealmente correlacionadas (K-NN):**
``pressure [MPa]``, ``mass_flux [kg/m2-s]``, y ``length [mm]``

## ğŸ¤–MODELADO ENSEMBLE

**XGBRegressor**

**LightGBoostRegresor**

**CatBoostRegressor**

**GradientBoostingRegressor**

**RandomForestRegressor**



**``Mejor modelo``:** 

**``XGBRegressor``**

![modelos](img/best_rmse.png)
